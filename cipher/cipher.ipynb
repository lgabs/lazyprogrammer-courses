{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:33:49.244841Z",
     "start_time": "2020-06-29T00:33:48.747401Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:33:49.869639Z",
     "start_time": "2020-06-29T00:33:49.854735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# create substitution cipher \n",
    "\n",
    "letters1 = list(string.ascii_lowercase)\n",
    "letters2 = list(string.ascii_lowercase)\n",
    "\n",
    "print(letters1)\n",
    "\n",
    "# shuffle second list\n",
    "random.shuffle(letters2)\n",
    "\n",
    "true_mappings = {}\n",
    "for k,v in zip(letters1, letters2):\n",
    "    true_mappings[k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This true mapping is the one only known, theoretically, by the sender and receiver, not by the intruder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:33:51.772983Z",
     "start_time": "2020-06-29T00:33:51.761013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 'r', 'b': 'f', 'c': 'b', 'd': 'm', 'e': 'j', 'f': 'd', 'g': 'y', 'h': 'c', 'i': 'x', 'j': 't', 'k': 'e', 'l': 'i', 'm': 'h', 'n': 'a', 'o': 'g', 'p': 'q', 'q': 'z', 'r': 'l', 's': 'n', 't': 'u', 'u': 'v', 'v': 'w', 'w': 'k', 'x': 'p', 'y': 'o', 'z': 's'}\n"
     ]
    }
   ],
   "source": [
    "print(true_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:33:57.880940Z",
     "start_time": "2020-06-29T00:33:57.861593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 98, 99)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leveraging ord function to get integers from a character to use as index\n",
    "ord(\"a\"), ord(\"b\"), ord(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:19.306161Z",
     "start_time": "2020-06-29T00:34:19.272596Z"
    }
   },
   "outputs": [],
   "source": [
    "# markov matrix to store bigram probabilities\n",
    "# we initialize with ones to consider \"add-one smoothing\"\n",
    "M = np.ones((26,26))\n",
    "\n",
    "# initial state distribution (unigrams probabilities)\n",
    "pi = np.zeros(26)\n",
    "\n",
    "def update_bigrams(ch1, ch2):\n",
    "    i = ord(ch1) - 97\n",
    "    j = ord(ch2) - 97\n",
    "    M[i,j] += 1\n",
    "    \n",
    "def update_unigrams(ch):\n",
    "    i = ord(ch) - 97\n",
    "    pi[i] += 1\n",
    "    \n",
    "# get log-probability of a word/token\n",
    "def get_word_prob(word):\n",
    "    \n",
    "    probs = []\n",
    "    # first word index\n",
    "    i = ord(word[0]) - 97\n",
    "    probs.append(np.log(pi[i]))\n",
    "    \n",
    "    # rest of sentence\n",
    "    for w_previous, w in zip(word, word[1:]):\n",
    "        i = ord(w_previous) - 97\n",
    "        j = ord(w) - 97\n",
    "        probs.append(np.log(M[i,j]))\n",
    "        \n",
    "    # find log-probability\n",
    "    return sum(probs)\n",
    "\n",
    "# get log-probability of a document, which is a sequence of words\n",
    "def get_sequence_prob(doc:Union[str, List]):\n",
    "    \n",
    "    if type(doc) == str:\n",
    "        doc = doc.split()\n",
    "        \n",
    "    prob = 0\n",
    "    for word in doc:\n",
    "        prob += get_word_prob(word)\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Language Model from Moby Dick Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:25.464475Z",
     "start_time": "2020-06-29T00:34:22.945878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading moby dick book...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"moby_dick.txt\"):\n",
    "    print(\"downloading moby dick book...\")\n",
    "    r = requests.get(\"https://lazyprogrammer.me/course_files/moby_dick.txt\")\n",
    "    with open(\"moby_dick.txt\", \"w\") as f:\n",
    "        f.write(r.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:26.603502Z",
     "start_time": "2020-06-29T00:34:26.458645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cipher.ipynb  moby_dick.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:32.205991Z",
     "start_time": "2020-06-29T00:34:31.489885Z"
    }
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "for line in open('moby_dick.txt', 'r'):\n",
    "    line = line.rstrip()\n",
    "    if line:\n",
    "        # replace non-alpha characters with space\n",
    "        line = regex.sub(' ', line) \n",
    "        tokens = line.lower().split()\n",
    "        \n",
    "        # update our language model \n",
    "        for token in tokens:\n",
    "            # update first unigram letter\n",
    "            ch0 = token[0]\n",
    "            update_unigrams(ch0)\n",
    "            \n",
    "            # update bigrams for the other letters\n",
    "            for ch1 in token[1:]:\n",
    "                update_bigrams(ch0, ch1)\n",
    "                ch0 = ch1\n",
    "\n",
    "# normalize probabilities\n",
    "pi /= pi.sum()\n",
    "M /= M.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:33.389291Z",
     "start_time": "2020-06-29T00:34:33.383684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7.04046861e-05, 2.76127179e-02, 3.36111972e-02, 4.38621195e-02,\n",
       "         4.22428117e-04, 8.73018108e-03, 2.05018446e-02, 1.08704835e-02,\n",
       "         4.75090822e-02, 2.95699682e-04, 1.45456082e-02, 1.10633924e-01,\n",
       "         2.53034442e-02, 2.09721479e-01, 2.11214058e-04, 2.34306795e-02,\n",
       "         7.04046861e-05, 1.08395055e-01, 9.77076234e-02, 1.42217466e-01,\n",
       "         7.92756766e-03, 2.33602749e-02, 1.04198935e-02, 4.50589991e-04,\n",
       "         2.94854826e-02, 2.63313526e-03],\n",
       "        [6.00292826e-02, 2.66089503e-02, 6.36577758e-05, 5.72919982e-04,\n",
       "         2.54949392e-01, 6.36577758e-05, 1.27315552e-04, 4.45604431e-04,\n",
       "         3.79400344e-02, 5.47456872e-03, 6.36577758e-05, 1.20567827e-01,\n",
       "         8.91208861e-04, 1.27315552e-04, 1.52333057e-01, 6.36577758e-05,\n",
       "         6.36577758e-05, 5.88197848e-02, 1.89063594e-02, 7.25698644e-03,\n",
       "         1.67483608e-01, 8.27551085e-04, 1.27315552e-04, 6.36577758e-05,\n",
       "         8.60653129e-02, 6.36577758e-05]]), array([0.10945403]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:2], pi[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:38.550764Z",
     "start_time": "2020-06-29T00:34:38.541038Z"
    }
   },
   "outputs": [],
   "source": [
    "### encode a message\n",
    "\n",
    "# this is a random excerpt from Project Gutenberg's\n",
    "# The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
    "# https://www.gutenberg.org/ebooks/1661\n",
    "\n",
    "original_message = '''I then lounged down the street and found,\n",
    "as I expected, that there was a mews in a lane which runs down\n",
    "by one wall of the garden. I lent the ostlers a hand in rubbing\n",
    "down their horses, and received in exchange twopence, a glass of\n",
    "half-and-half, two fills of shag tobacco, and as much information\n",
    "as I could desire about Miss Adler, to say nothing of half a dozen\n",
    "other people in the neighbourhood in whom I was not in the least\n",
    "interested, but whose biographies I was compelled to listen to.\n",
    "'''\n",
    "\n",
    "# Away they went, and I was just wondering whether I should not do well\n",
    "# to follow them when up the lane came a neat little landau, the coachman\n",
    "# with his coat only half-buttoned, and his tie under his ear, while all\n",
    "# the tags of his harness were sticking out of the buckles. It hadn't\n",
    "# pulled up before she shot out of the hall door and into it. I only\n",
    "# caught a glimpse of her at the moment, but she was a lovely woman, with\n",
    "# a face that a man might die for.\n",
    "\n",
    "# My cabby drove fast. I don't think I ever drove faster, but the others\n",
    "# were there before us. The cab and the landau with their steaming horses\n",
    "# were in front of the door when I arrived. I paid the man and hurried\n",
    "# into the church. There was not a soul there save the two whom I had\n",
    "# followed and a surpliced clergyman, who seemed to be expostulating with\n",
    "# them. They were all three standing in a knot in front of the altar. I\n",
    "# lounged up the side aisle like any other idler who has dropped into a\n",
    "# church. Suddenly, to my surprise, the three at the altar faced round to\n",
    "# me, and Godfrey Norton came running as hard as he could towards me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:42.896109Z",
     "start_time": "2020-06-29T00:34:42.879308Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_msg(msg):\n",
    "    \n",
    "    # lowercase everything and remove non-alpha charcaters\n",
    "    msg = msg.lower()\n",
    "    msg = regex.sub(\" \", msg)\n",
    "    \n",
    "    coded_msg = []\n",
    "    for ch in msg:\n",
    "        coded_ch = ch\n",
    "        if ch in true_mappings:\n",
    "            coded_ch = true_mappings[ch]\n",
    "        coded_msg.append(coded_ch)\n",
    "            \n",
    "    return \"\".join(coded_msg)\n",
    "\n",
    "def decode_msg(msg, word_mapping):\n",
    "    decoded_msg = []\n",
    "    for ch in msg:\n",
    "        decoded_ch = ch\n",
    "        if ch in word_mapping:\n",
    "            decoded_ch = word_mapping[ch]\n",
    "        decoded_msg.append(decoded_ch)\n",
    "            \n",
    "    return \"\".join(decoded_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:43.829926Z",
     "start_time": "2020-06-29T00:34:43.816156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x ucja igvayjm mgka ucj nuljju ram dgvam  rn x jpqjbujm  ucru ucjlj krn r hjkn xa r iraj kcxbc lvan mgka fo gaj krii gd ucj yrlmja  x ijau ucj gnuijln r cram xa lvffxay mgka ucjxl cglnjn  ram ljbjxwjm xa jpbcrayj ukgqjabj  r yirnn gd crid ram crid  ukg dxiin gd ncry ugfrbbg  ram rn hvbc xadglhruxga rn x bgvim mjnxlj rfgvu hxnn rmijl  ug nro agucxay gd crid r mgsja gucjl qjgqij xa ucj ajxycfgvlcggm xa kcgh x krn agu xa ucj ijrnu xaujljnujm  fvu kcgnj fxgylrqcxjn x krn bghqjiijm ug ixnuja ug  \n"
     ]
    }
   ],
   "source": [
    "encoded_msg = encode_msg(original_message)\n",
    "print(encoded_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Evolutionary Algorithm to decode messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:34:50.138882Z",
     "start_time": "2020-06-29T00:34:50.124077Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_dna_pool(n=20):\n",
    "    dna_pool = []\n",
    "    for _ in range(n):\n",
    "        dna = list(string.ascii_lowercase)\n",
    "        random.shuffle(dna)\n",
    "        dna_pool.append(dna)\n",
    "    \n",
    "    return dna_pool\n",
    "\n",
    "def procriate_offspring(dna_pool, n_children=3):\n",
    "    \n",
    "    offspring = []\n",
    "    for parent in dna_pool:\n",
    "        for _ in range(n_children):\n",
    "            copy = parent.copy()\n",
    "            i = np.random.randint(len(copy))\n",
    "            j = np.random.randint(len(copy))\n",
    "            \n",
    "            # swap characters\n",
    "            tmp = copy[i]\n",
    "            copy[i] = copy[j]\n",
    "            copy[j] = tmp\n",
    "            \n",
    "            offspring.append(copy)\n",
    "            \n",
    "    return offspring + dna_pool\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:43:56.931391Z",
     "start_time": "2020-06-29T00:43:56.920314Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model(n_epochs=100):\n",
    "    \n",
    "    n_survivals = 5\n",
    "    scores = np.zeros(n_epochs)\n",
    "    best_dna = None\n",
    "    best_map = None\n",
    "    best_score = float('-inf')\n",
    "    \n",
    "    dna_pool = generate_dna_pool()\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        if i > 0:\n",
    "            dna_pool = procriate_offspring(dna_pool, n_survivals)\n",
    "\n",
    "        # calculate score for each dna\n",
    "        dna2score = {}\n",
    "        for dna in dna_pool:\n",
    "            # build a map from current dna sequence\n",
    "            current_map = {}\n",
    "            for k,v in zip(letters1, dna):\n",
    "                current_map[k] = v\n",
    "\n",
    "            # decode using current map    \n",
    "            decoded_msg = decode_msg(encoded_msg, current_map)\n",
    "            score = get_sequence_prob(decoded_msg)\n",
    "\n",
    "            # store this result\n",
    "            dna2score[''.join(dna)] = score\n",
    "\n",
    "            # check if this score is better than the best\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_dna = dna\n",
    "                best_map = current_map\n",
    "\n",
    "        scores[i] = np.mean(list(dna2score.values()))\n",
    "\n",
    "        # keep the best DNAs, survival of the fittest, using n_survivals\n",
    "        sorted_dna = sorted(dna2score.items(), key=lambda x: x[1], reverse=True)\n",
    "        dna_pool = [list(k) for k,v in sorted_dna[:n_survivals]]\n",
    "#         [list(k) for k, v in sorted_dna[:5]]\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(\"iter:\", i, \"score:\", scores[i], \"best so far:\", best_score)\n",
    "        \n",
    "    return best_dna, best_map, best_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:44:17.317123Z",
     "start_time": "2020-06-29T00:43:57.344154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 score: -2062.184439056681 best so far: -1774.5103379069421\n",
      "iter: 200 score: -1036.0586442040906 best so far: -929.5902922650557\n",
      "iter: 400 score: -1021.5983857358721 best so far: -929.5902922650557\n",
      "iter: 600 score: -1066.9281144808915 best so far: -929.5902922650557\n",
      "iter: 800 score: -1029.7864992265195 best so far: -929.5902922650557\n"
     ]
    }
   ],
   "source": [
    "# Run the evolution!\n",
    "n_epochs = 1000\n",
    "best_dna, best_map, best_score, scores = run_model(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:44:17.930603Z",
     "start_time": "2020-06-29T00:44:17.908815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL of decoded with best mapping:  -929.5902922650557\n",
      "LL of original mapping:  -933.0312453751817\n",
      "true: k, pred: q\n",
      "true: q, pred: z\n",
      "true: z, pred: k\n"
     ]
    }
   ],
   "source": [
    "# use best score\n",
    "decoded_msg = decode_msg(encoded_msg, best_map)\n",
    "\n",
    "print(\"LL of decoded with best mapping: \", get_sequence_prob(decoded_msg))\n",
    "print(\"LL of original mapping: \", get_sequence_prob(regex.sub(\" \", original_message.lower())))\n",
    "\n",
    "for true, v in true_mappings.items():\n",
    "    pred = best_map[v] # best map is a reverse map\n",
    "    if true != pred:\n",
    "        print(f\"true: {true}, pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:46:37.647464Z",
     "start_time": "2020-06-29T00:46:37.636113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded message:\n",
      "\n",
      " i then lounged down the street and found  as i expected  that there\n",
      "was a mews in a lane which runs down by one wall of the garden  i lent\n",
      "the ostlers a hand in rubbing down their horses  and received in\n",
      "exchange twopence  a glass of half and half  two fills of shag tobacco\n",
      "and as much information as i could desire about miss adler  to say\n",
      "nothing of half a doken other people in the neighbourhood in whom i\n",
      "was not in the least interested  but whose biographies i was compelled\n",
      "to listen to\n",
      "\n",
      "original message:\n",
      "\n",
      " I then lounged down the street and found,\n",
      "as I expected, that there was a mews in a lane which runs down\n",
      "by one wall of the garden. I lent the ostlers a hand in rubbing\n",
      "down their horses, and received in exchange twopence, a glass of\n",
      "half-and-half, two fills of shag tobacco, and as much information\n",
      "as I could desire about Miss Adler, to say nothing of half a dozen\n",
      "other people in the neighbourhood in whom I was not in the least\n",
      "interested, but whose biographies I was compelled to listen to.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"decoded message:\\n\\n\", textwrap.fill(decoded_msg)) \n",
    "\n",
    "print(\"\\noriginal message:\\n\\n\", original_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('rasa': conda)",
   "language": "python",
   "name": "python37664bitrasacondad9145d6131674bb8ab1bad5e27d9d755"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
